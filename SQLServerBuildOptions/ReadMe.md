---

# **SQL Server HA Design Evaluation for BizTalk 2020 Migration**

## **1. Purpose**

This document evaluates options for SQL Server high availability (HA) in the upcoming migration from BizTalk Server 2016 (on SQL 2016 and Windows 2012 R2) to **BizTalk Server 2020 on SQL Server 2022 Standard and Windows Server 2022**.

We assess alternatives to the existing **WSFC-based setup** using technical, operational, and licensing perspectives.

---

## **2. Current Architecture (Source)**

| Component          | Detail                                   |
| ------------------ | ---------------------------------------- |
| BizTalk Version    | BizTalk Server 2016                      |
| SQL Server Version | SQL Server 2016 Standard                 |
| OS                 | Windows Server 2012 R2                   |
| SQL HA Model       | WSFC (Windows Server Failover Cluster)   |
| Cluster Quorum     | **File Share Witness** (no disk witness) |
| Shared Storage     | **RDM (Raw Device Mapping)** via VMware  |
| Backups            | Database-level backups via **Rubrik**    |
| VMware             | Fully redundant vSphere infra (HA + DRS) |
| VM Backups         | âŒ No image-level VM backups              |

---

## **3. Target Architecture (To-Be)**

| Component          | Detail                        |
| ------------------ | ----------------------------- |
| BizTalk Version    | BizTalk Server 2020           |
| SQL Server Version | SQL Server 2022 Standard      |
| OS                 | Windows Server 2022           |
| SQL HA Model       | **Under evaluation**          |
| Backups            | Rubrik (unchanged)            |
| VMware             | Redundant vSphere (unchanged) |

---

## **4. SQL HA Options Under Review**

The following SQL Server HA/DR design options are being considered for the target BizTalk 2020 environment:

| Options      | Description                                                                                                                   |
| ------------ | ----------------------------------------------------------------------------------------------------------------------------- |
| **1** | **Single SQL Server** â€” One SQL VM only, no HA or DR configuration                                                            |
| **2** | **Single SQL Server + Cold Standby** â€” Standby VM prebuilt but inactive, used for manual recovery                             |
| **3** | **Basic Availability Groups (SQL Standard Edition)** â€” Two SQL VMs with per-database AGs and DNS-based failover               |
| **4** | **Windows Server Failover Cluster (WSFC)** â€” Two-node cluster using shared RDM storage and file share witness **(current model)** |


### âœ… **Option 1: Single SQL Server (No HA)**

One SQL VM running all BizTalk databases. No failover, cluster, or standby.

* OS crash = **full VM rebuild**, SQL install, Rubrik restore, DB consistency check
* VMware HA covers host failure only (VM restarts elsewhere)

**RTO**: ğŸ”´ 4â€“8 hours
**Data Redundancy**: âŒ None

**Pros**:

* Simplest setup
* Lowest licensing cost

**Cons**:

* Single point of failure
* Manual rebuild & validation
* Unacceptable for production in most orgs

---

### ğŸŸ  **Option 2: Single SQL Server + Cold Standby**

Second SQL Server VM built and patched, but **not active**. Activated only during disaster.

* Failure = Promote standby â†’ Restore from Rubrik â†’ Run DBCC checks
* Faster recovery than Option 1 but **not automatic**

**RTO**: ğŸŸ  2â€“4 hours
**Data Redundancy**: âŒ None (until restored)

**Pros**:

* Minimal infra cost beyond Option 1
* Quicker than full rebuild
* No shared disk or clustering needed

**Cons**:

* No automatic failover
* Requires manual restore + checks
* Data loss within last backup window

---

### ğŸŸ¡ **Option 3: Basic Availability Groups (SQL Standard Edition)**

* Two SQL Server VMs with **Basic Always On AG**
* Each database in its own AG (SQL Std supports only 1 DB per AG)
* Uses **BizTalk DNS alias (CNAME)** pointing to primary SQL instance

**Failover Steps**: Fail AG manually â†’ Update DNS alias to new primary â†’ BizTalk reconnects

**RTO**: ğŸŸ¢ 15â€“30 minutes (manual DNS update)
**Data Redundancy**: âœ… Two full database copies

**Pros**:

* Real-time synchronization
* Built-in redundancy of data
* No shared storage required

**Cons**:

* Requires manual DNS repointing (no built-in listener support in SQL Std)
* Slight complexity due to per-DB AG setup
* Must validate BizTalk compatibility with CNAME failover

---

### ğŸŸ¢ **Option 4: WSFC with RDM Shared Disk (Current Model)**

* Two-node WSFC cluster using **shared storage (RDM via VMware)**
* Witness is a **file share**, not a quorum disk
* BizTalk connects via instance name; failover is **fully transparent**

**RTO**: ğŸŸ¢ <2 minutes (automatic failover)
**Data Redundancy**: âŒ No second copy (single shared disk)

**Pros**:

* Proven and familiar BizTalk HA model
* Automatic failover â€” seamless to applications
* No application logic change or DNS management

**Cons**:

* Only **one copy of data** (shared disk = single point of failure)
* Shared storage adds complexity (RDM mapping, zoning, etc.)
* Not cloud-friendly or flexible in modern deployments

---

## **5. Technical Comparison Table**

| Feature / Criteria        | Option 1<br>(Single) | Option 2<br>(+Standby) | Option 3<br>(Basic AG) | Option 4<br>(WSFC RDM) |
| ------------------------- | -------------------- | ---------------------- | ---------------------- | ---------------------- |
| HA / Failover Type        | âŒ None               | âŒ None                 | ğŸŸ¡ Manual (DNS)        | âœ… Automatic            |
| Data Redundancy           | âŒ None               | âŒ None                 | âœ… Yes (2 copies)       | âŒ No (shared disk)     |
| Storage Dependency        | ğŸŸ¢ None              | ğŸŸ¢ None                | ğŸŸ¢ Local disks         | ğŸ”´ RDM Shared Disk     |
| Shared Storage Required   | âŒ No                 | âŒ No                   | âŒ No                   | âœ… Yes (RDM)            |
| Witness / Quorum          | N/A                  | N/A                    | N/A                    | âœ… File Share Witness   |
| Failover Complexity       | ğŸ”´ Full rebuild      | ğŸŸ  Manual restore      | ğŸŸ¡ DNS update needed   | ğŸŸ¢ Seamless            |
| VMware HA Coverage        | âœ… Yes                | âœ… Yes                  | âœ… Yes                  | âœ… Yes                  |
| Licensing Required        | 1 Std                | 1 Std (+DR rights)     | 2 Std                  | 2 Std                  |
| BizTalk Compatibility     | âœ… Yes                | âœ… Yes                  | âš ï¸ Must test CNAME     | âœ… Fully Supported      |
| RTO (Real World)          | ğŸ”´ 4â€“8+ hrs          | ğŸŸ  2â€“4 hrs             | ğŸŸ¢ \~30 min            | ğŸŸ¢ <2 min              |
| DBA Workload Post-Failure | ğŸ”´ High              | ğŸŸ  Medium              | ğŸŸ¡ Low                 | ğŸŸ¢ Low                 |

---

## **6. Recommendation Summary**

| Priority                     | Recommended Option          |
| ---------------------------- | --------------------------- |
| âœ… **Seamless BizTalk HA**    | **Option 4 â€“ WSFC (RDM)**   |
| âœ… **Data redundancy needed** | **Option 3 â€“ Basic AG**     |
| ğŸ’° **Cost-aware DR only**    | **Option 2 â€“ Cold Standby** |
| ğŸš« **Non-prod / Dev only**   | **Option 1 â€“ Single SQL**   |

---

## **7. Final Notes**

* **VMware HA/DRS** already ensures **automatic recovery from ESXi host failure**
* Failures like **OS corruption** still require **VM rebuild** and **DB validation**
* **Rubrik** is the backup/restore method â€” **DBCC checks are mandatory** post-recovery
* BizTalk 2020 must be validated to work with **DNS alias failover** (Option 3)
* WSFC still has a **single storage failure domain** due to shared RDM

---

## **8. Action Items**

| Task                                                   | Owner        | Status    |
| ------------------------------------------------------ | ------------ | --------- |
| Validate DNS alias-based failover with BizTalk 2020    | BizTalk Team | â³ Pending |
| Confirm licensing position for cold standby (Option 2) | Licensing/IT | â³ Pending |
| Review NAS/RDM storage redundancy                      | Infra Team   | â³ Pending |
| Document Rubrik + DB consistency check SOP             | DBAs         | â³ Pending |
| Consider scripting DNS update for Option 3             | Infra/DevOps | â³ Pending |

---

---
##ğŸ” APPENDIX: **Option Smmary**
---

## âœ… **Option 1: Single SQL Server (No HA)**

| **Configuration Description**                                                                                                                                                                                                       | **Failover / Recovery Process**                           | **RTO**      | **Data Redundancy** | **Pros**                                    | **Cons**                                                                                                 |
| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------- | ------------ | ------------------- | ------------------------------------------- | -------------------------------------------------------------------------------------------------------- |
| â€¢ One SQL VM running all BizTalk databases<br>â€¢ No failover, cluster, or standby<br>â€¢ OS crash = full VM rebuild, SQL install, Rubrik restore, DB consistency check<br>â€¢ VMware HA covers host failure only (VM restarts elsewhere) | Rebuild VM â†’ Install SQL â†’ Restore from Rubrik â†’ Run DBCC | ğŸ”´ 4â€“8 hours | âŒ None              | â€¢ Simplest setup<br>â€¢ Lowest licensing cost | â€¢ Single point of failure<br>â€¢ Manual rebuild & validation<br>â€¢ Unacceptable for production in most orgs |

---

## ğŸŸ  **Option 2: Single SQL Server + Cold Standby**

| **Configuration Description**                                                                                                                                                                           | **Failover / Recovery Process**                                              | **RTO**      | **Data Redundancy**     | **Pros**                                                                                                     | **Cons**                                                                                                     |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | ------------ | ----------------------- | ------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------ |
| â€¢ Second SQL Server VM built and patched, but not active<br>â€¢ Activated only during disaster<br>â€¢ Failure = promote standby, restore from Rubrik, run DBCC<br>â€¢ Faster than Option 1, but not automatic | Power on standby â†’ Restore databases â†’ Run DBCC â†’ Update BizTalk connections | ğŸŸ  2â€“4 hours | âŒ None (until restored) | â€¢ Minimal infra cost beyond Option 1<br>â€¢ Quicker than full rebuild<br>â€¢ No shared disk or clustering needed | â€¢ No automatic failover<br>â€¢ Manual restore & consistency checks<br>â€¢ Data loss risk from last backup window |

---

## ğŸŸ¡ **Option 3: Basic Availability Groups (SQL Standard Edition)**

| **Configuration Description**                                                                                                                                                                                                           | **Failover / Recovery Process**                            | **RTO**          | **Data Redundancy**        | **Pros**                                                                                  | **Cons**                                                                                                                                          |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------- | ---------------- | -------------------------- | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |
| â€¢ Two SQL Server VMs with Basic Always On AG<br>â€¢ Each database in its own AG (SQL Std supports only 1 DB per AG)<br>â€¢ Uses BizTalk DNS alias (CNAME) pointing to active SQL instance<br>â€¢ Requires manual DNS alias update on failover | Manual AG failover â†’ Update CNAME/DNS â†’ BizTalk reconnects | ğŸŸ¢ 15â€“30 minutes | âœ… Two full database copies | â€¢ Real-time synchronization<br>â€¢ Built-in data redundancy<br>â€¢ No shared storage required | â€¢ Manual DNS repointing (no AG listener in SQL Std)<br>â€¢ One DB per AG = more complexity<br>â€¢ Must test BizTalk compatibility with CNAME failover |

---

## ğŸŸ¢ **Option 4: WSFC with RDM Shared Disk (Current Model)**

| **Configuration Description**                                                                                                                                                                                            | **Failover / Recovery Process**                            | **RTO**       | **Data Redundancy**            | **Pros**                                                                                                   | **Cons**                                                                                                                           |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------- | ------------- | ------------------------------ | ---------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |
| â€¢ Two-node WSFC cluster using shared storage (RDM via VMware)<br>â€¢ Witness is a file share (not quorum disk)<br>â€¢ Only one node is active at a time<br>â€¢ BizTalk connects via SQL instance name; failover is transparent | Automatic WSFC failover â†’ BizTalk reconnects transparently | ğŸŸ¢ <2 minutes | âŒ No second copy (shared disk) | â€¢ Proven BizTalk HA model<br>â€¢ Seamless automatic failover<br>â€¢ No application logic or DNS changes needed | â€¢ Only one copy of data (shared RDM = SPOF)<br>â€¢ VMware + storage management overhead<br>â€¢ Not flexible for cloud or hybrid setups |

---

---

## ğŸ” APPENDIX: End-to-End RDM Presentation Flow: PowerMax 2000 â ESXi â VM for WSFC Scenario

---

### **1. PowerMax 2000 (Storage Array) â€“ Provisioning the LUN**

On the **PowerMax 2000**:

* **Create a LUN** (or Volume) in Unisphere or via Solutions Enabler/REST API.
* Mask the LUN to the **ESXi hosts** using a **Storage Group** and **Masking View**:

  * Add the LUN to a **Storage Group**.
  * Ensure the correct **Initiator Group** (host WWNs from the ESXi HBAs) is included.
  * Associate the Storage Group and Initiator Group via a **Masking View**.
* Confirm that LUN is **visible to the ESXi hosts** through FC or iSCSI.

> ğŸ“ At this point, each ESXi host can "see" the raw LUN via its storage fabric.

---

### **2. ESXi â€“ Detecting and Making the LUN Available**

On **vSphere/ESXi**:

* Rescan storage adapters in **vSphere Client** or via CLI:

  ```bash
  esxcli storage core adapter rescan --all
  ```
* The LUN should appear under:
  **Storage > Devices** with an identifier like `naa.600009700001xxxxx` or `vml.02...`.

> ğŸš¨ Important: You **do not create a datastore** on this LUN â€” it's meant to be used raw.

---

### **3. vSphere â€“ Assigning LUN to a VM as an RDM**

Now, to present the LUN as an **RDM disk** to a **VM**:

1. **Edit VM settings** â†’ Add **New Hard Disk** â†’ Select **Raw Device Mapping**.
2. Choose the correct **device (LUN)** from the list of available SAN devices.
3. Select:

   * **Compatibility Mode**: *Physical* or *Virtual*
   * **Location**: Where the small RDM pointer file (a .vmdk stub) will be stored (typically in the VM's datastore folder).
4. Choose the **SCSI controller** and **Bus Sharing mode** if needed:

   * For shared-disk clustering, use the **same SCSI bus number** across VMs and enable **Physical SCSI Bus Sharing**.
5. Save and power on the VM.

> âœ… Now the guest OS sees the PowerMax LUN as a **native SCSI disk**.

---

### **4. Inside the VM â€“ Using the RDM**

In the **guest OS**:

* The disk appears as a **native SCSI device**, not virtualized.
* You can format, partition, or use it for clustering (e.g., Failover Cluster, Oracle ASM, etc.).
* Applications that require **raw block-level access** (like SAN-based backups or database clusters) can now directly interact with the storage.

---

## ğŸ” Diagram Summary

```plaintext
[PowerMax 2000 LUN]
       â”‚
       â–¼
[Storage Group + Masking View]
       â”‚
       â–¼
[FC/iSCSI Network]
       â”‚
       â–¼
[ESXi Host HBA]
       â”‚
       â–¼
[vSphere sees LUN as raw device]
       â”‚
       â–¼
[Assign to VM as RDM disk (Physical Mode)]
       â”‚
       â–¼
[Guest OS sees it as a SCSI disk]
```

---

## âœ… Key Benefits of This Setup

* Low-latency, block-level access
* Required for MSCS/WSFC or Oracle RAC
* Enables SAN-based backup or replication
* Bypasses VMware file system (VMFS) overhead

---

